
<!doctype html>
<html lang="en">
  <head>
  <script src="https://use.fontawesome.com/baff6f55f5.js"></script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Tyler Ransom by tyleransom</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/github-light.css">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=yes">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
      ga('create', 'UA-29643011-3', 'auto');
      ga('send', 'pageview');
    </script>

    <!-- New GA4 tracking code, see https://support.google.com/analytics/answer/10271001#analyticsjs-enable-basic -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-311521642"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-311521642');
    </script>

    <!-- For all browsers -->
    <link rel="stylesheet" href="assets/css/academicons.min.css"/>
    <link rel="stylesheet" href="assets/css/academicons.css"/>

    <style>
      button.accordion {
      font:14px/1.5 Lato, "Helvetica Neue", Helvetica, Arial, sans-serif;
      cursor: pointer;
      padding: 0px;
      border: none;
      text-align: left;
      outline: none;
      font-size: 100%;
      transition: 0.3s;
      background-color: #f8f8f8;
      }
      button.accordion.active, button.accordion:hover {
      background-color: #f8f8f8;
      }
      button.accordion:after {
      content: " [+] ";
      font-size: 90%;
      color:#777;
      float: left;
      margin-left: 1px;
      }

      button.accordion.active:after {
      content: " [\2212] ";
      }
      div.panel {
      padding: 0 20px;
      margin-top: 5px;
      display: none;
      background-color: white;
      font-size: 100%;
      }
      div.panel.show {
      display: block !important;
      }
      .social-row {
        display: flex;
        flex-wrap: wrap;
        justify-content: space-between;
      }
    </style>
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>Ruxin Wang</h1>
        <p>Associate Professor<br>Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences</p>
        <!-- <p>Research Affiliate<br><a href="http://legacy.iza.org/en/webcontent/personnel/photos/index_html?key=24155">Institute for the Study of Labor (IZA)</a></p> -->
    <h3><a href="https://mathwrx.github.io/">Home</a></h3>
        <h3><a href="https://mathwrx.github.io/research.html">Research</a></h3>
    <!-- <h3><a href="https://tyleransom.github.io/research/CV.pdf">CV</a></h3>   -->
        <!-- <h3><a href="https://tyleransom.github.io/code.html">Code</a></h3>  -->
        <!-- <h3><a href="https://tyleransom.github.io/teaching.html">Teaching</a></h3>  -->
        <!-- <h3><a href="https://tyleransom.github.io/personal.html">Personal</a></h3> -->
    <b>Social</b><br>
        <div class="social-row">
          <a href="mailto:rx.wang@siat.ac.cn." class="author-social" target="_blank"><i class="fa fa-fw fa-envelope-square"></i> Email</a><br>
          <!-- <a href="https://scholar.google.com/citations?user=eohlTTcAAAAJ&hl=en" target="_blank"><i class="ai ai-fw ai-google-scholar-square"></i> Scholar</a><br> -->
          <a href="https://orcid.org/0000-0003-4772-3284"><i class="ai ai-fw ai-orcid-square"></i> ORCID</a><br>
          <!-- <a href="http://ideas.repec.org/f/pra541.html"><i class="fa fa-fw fa-share-alt-square"></i> RePEc</a><br> -->
          <a href="http://github.com/mathwrx"><i class="fa fa-fw fa-github-square"></i> GitHub</a><br>
          <!-- <a href="http://twitter.com/tyleransom" class="author-social" target="_blank"><i class="fa fa-fw fa-twitter-square"></i> Twitter</a><br> -->
          <!-- <a href="http://linkedin.com/in/tyleransom" class="author-social" target="_blank"><i class="fa fa-fw fa-linkedin-square"></i> LinkedIn</a><br> -->
          <br>
        </div>
        <br>

    <p><b>Contact:</b><br>Institute of Advanced Computing and<br>Digital Engineering<br>Shenzhen Institutes of Advanced<br>Technology, CAS<br>1068 Xueyuan Avenue, Shenzhen<br>University Town<br>Shenzhen, 518055</p>
    <p><small>Hosted on GitHub Pages</small></p>

      </header>
      <section>

    <!-- <h2><a id="recent-RRs-updated" class="anchor" href="#RRpapers" aria-hidden="true"><span class="octicon octicon-link"></span></a>Papers under Review</h2>
    <p style="margin:0"> <a style="margin:0; font-size:100%; font-weight:bold" href="https://tyleransom.github.io/research/CollegeDropout2016May31.pdf">College Attrition and the Dynamics of Information Revelation</a> <br> with <a href="http://public.econ.duke.edu/~psarcidi/">Peter Arcidiacono</a>, <a href="https://sites.google.com/site/estebanmaucejo/">Esteban Aucejo</a>, and <a href="http://www.amaurel.net/">Arnaud Maurel</a> <br> <b>R &amp; R, <i>Journal of Political Economy</i></b> (updated May 31, 2016) <br><button class="accordion">
      Abstract
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> This paper investigates the role played by informational frictions in college and the workplace. We estimate a dynamic structural model of schooling and work decisions, where individuals have imperfect information about their schooling ability and labor market productivity. We take into account the heterogeneity in schooling investments by distinguishing between two- and four-year colleges, graduate school, as well as science and non-science majors for four-year colleges. Individuals may also choose whether to work full-time, part-time, or not at all. A key feature of our approach is to account for correlated learning through college grades and wages, whereby individuals may leave or re-enter college as a result of the arrival of new information on their ability and productivity. Our findings indicate that the elimination of informational frictions would increase the college graduation rate by 9 percentage points, and would increase the college wage premium by 32.7 percentage points through increased sorting on ability. </p></div>
    <p style="margin:0"><button class="accordion">
      Other versions
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> <a href="http://www.nber.org/papers/w22325">NBER Working Paper No. 22325</a> (June 2016) </p></div><br>

    <hr>

    <h2><a id="recent-papers-updated" class="anchor" href="#workingpapers" aria-hidden="true"><span class="octicon octicon-link"></span></a>Working Papers</h2>
    <p style="margin:0"> <a style="margin:0; font-size:100%; font-weight:bold" href="https://tyleransom.github.io/research/racialpref.pdf">What the Students for Fair Admissions Cases Reveal About Racial Preferences</a> <br> with <a href="http://public.econ.duke.edu/~psarcidi/">Peter Arcidiacono</a> and <a href="http://www.terry.uga.edu/directory/economics/josh-kinsler">Josh Kinsler</a> <br> (April 15, 2022) <br><button class="accordion">
    Abstract
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> Using detailed admissions data made public in the <i>SFFA v. Harvard</i> and <i>SFFA v. UNC</i> cases, we examine how racial preferences for under-represented minorities (URMs) affect their admissions to Harvard and UNC-Chapel Hill. At Harvard, the admit rates for typical African American applicants are on average over four times larger than if they had been treated as white. For typical Hispanic applicants the increase is 2.4 times. At UNC, preferences vary substantially by whether the applicant is in-state or out-of-state. For in-state applicants, racial preferences result in an over 70% increase in the African American admit rate. For out-of-state applicants, the increase is more than tenfold. Both universities provide larger racial preferences to URMs from higher socioeconomic backgrounds. </p></div>
    <p style="margin:0"><button class="accordion">
      Other versions
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> <br> <a href="http://www.nber.org/papers/w29964">NBER Working Paper No. 29964</a> (April 2022) <br> <a href="https://www.iza.org/publications/dp/15240/what-the-students-for-fair-admissions-cases-reveal-about-racial-preferences">IZA Discussion Paper No. 15240</a> (April 2022) </p></div>
    <p style="margin:0"><button class="accordion">
      Video presentation
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> <br> <a href="https://www.youtube.com/watch?v=D9gMyiAEtus">Hoover Institution</a> </p></div>
<!--
    <p style="margin:0"><button class="accordion">
      Online Appendix
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> <a href="https://tyleransom.github.io/research/RecruitRejectOnlineAppendix.pdf">Online Appendix</a> </p></div>
    <p style="margin:0"><button class="accordion">
      Replication files
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> <a href="https://github.com/tyleransom/Recruit-Reject-EER/releases/tag/v1.0">Data &amp; code for replication</a> <br> <a href="https://doi.org/10.5281/zenodo.6368299"><img src="https://zenodo.org/badge/471373775.svg" alt="DOI"></a> </p></div>
-->
    <!-- <p style="margin:0"><button class="accordion">
      Media coverage
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> <a href="https://marginalrevolution.com/marginalrevolution/2022/05/how-strong-are-the-racial-preferences-of-universities.html"><i>Marginal Revolution</i></a> <br> <a href="https://www.insidehighered.com/admissions/article/2022/05/02/study-sees-advantages-black-and-latinx-applicants-harvard-unc"><i>Inside Higher Ed</i></a> <br> <a href="https://www.audible.com/pd/Ep-55-Dr-Peter-Arcidiacono-Featured-Guest-Interview-Podcast/B09Z7V1H2H"><i>The Economics Review</i> podcast</a> <br> <a href="https://www.educationnext.org/the-education-exchange-how-race-factors-into-college-admissions/"><i>The Education Exchange</i> podcast</a> <br> <a href="https://podcasts.apple.com/us/podcast/mediocracy-and-affirmative-action-part-5/id1581181836?i=1000561519927"><i>The Genius of Thomas Sowell</i> podcast</a>  </p></div><br>

    <hr> -->

    <h2><a id="published-papers-updated" class="anchor" href="#publications" aria-hidden="true"><span class="octicon octicon-link"></span></a>Selected Published &amp; Forthcoming Papers (2020-)</h2>
    <p style="margin:0"> <a style="margin:0; font-size:100%; font-weight:bold" href="https://www.sciencedirect.com/science/article/pii/S1361841522000470">Boundary-aware context neural network for medical image segmentation</a> <br> <b>Wang, R.</b>, Chen, S., Ji, C., Fan, J., and Li, Y. <br> <i>Medical Image Analysis</i>, 78: 102395, 2022. <br><button class="accordion">
    Abstract
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> Medical image segmentation can provide a reliable basis for further clinical analysis and disease diagnosis. With the development of convolutional neural networks (CNNs), medical image segmentation performance has advanced significantly. However, most existing CNN-based methods often produce unsatisfactory segmentation masks without accurate object boundaries. This problem is caused by the limited context information and inadequate discriminative feature maps after consecutive pooling and convolution operations. Additionally, medical images are characterized by high intra-class variation, inter-class indistinction and noise, extracting powerful context and aggregating discriminative features for fine-grained segmentation remain challenging. In this study, we formulate a boundary-aware context neural network (BA-Net) for 2D medical image segmentation to capture richer context and preserve fine spatial information, which incorporates encoder-decoder architecture. In each stage of the encoder sub-network, a proposed pyramid edge extraction module first obtains multi-granularity edge information. Then a newly designed mini multi-task learning module for jointly learning segments the object masks and detects lesion boundaries, in which a new interactive attention layer is introduced to bridge the two tasks. In this way, information complementarity between different tasks is achieved, which effectively leverages the boundary information to offer strong cues for better segmentation prediction. Finally, a cross feature fusion module acts to selectively aggregate multi-level features from the entire encoder sub-network. By cascading these three modules, richer context and fine-grain features of each stage are encoded and then delivered to the decoder. The results of extensive experiments on five datasets show that the proposed BA-Net outperforms state-of-the-art techniques. </p></div>
    <!-- <p style="margin:0"><button class="accordion">
      Online Appendix -->
    <!-- </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> <a href="https://tyleransom.github.io/research/DivergentOnlineAppendix.pdf">Online Appendix</a> </p></div> -->
    <p style="margin:0"><button class="accordion">
      Replication files
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> <a href="https://github.com/mathwrx/BA-Net">Data &amp; code for replication</a> <br>  </p></div>
    <!-- <p style="margin:0"><button class="accordion">
      Other versions
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> <a href="https://tyleransom.github.io/research/divergent.pdf">Accepted version</a> (December 2021) <br> <a href="http://www.nber.org/papers/w26315">NBER Working Paper No. 26315</a> (September 2019) <br> <a href="https://www.iza.org/publications/dp/12634/divergent-the-time-path-of-legacy-and-athlete-admissions-at-harvard">IZA Discussion Paper No. 12634</a> <br> <a href="https://hceconomics.uchicago.edu/research/working-paper/divergent-time-path-legacy-and-athlete-admissions-harvard">HCEO Working Paper No. 2019-081</a> (December 2019) </p></div><br> -->
    <hr>
    <p style="margin:0"> <a style="margin:0; font-size:100%; font-weight:bold" href="https://www.sciencedirect.com/science/article/pii/S0957417422004791">Cascaded context enhancement network for automatic skin lesion segmentation</a> <br> <b>Wang, R.</b>, Chen, S., Ji, C., and Li, Y.<br> <i>Expert Systems with Applications</i>, 201: 117069, 2022.<br><button class="accordion">
      Abstract
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p>Skin lesion segmentation is an important step for automatic melanoma diagnosis. Due to the non-negligible diversity of lesions from different patients, extracting powerful context for fine-grained semantic segmentation is still challenging today. Although the deep convolutional neural networks (CNNs) have made significant improvements on skin lesion segmentation, they often fail to reserve the spatial details and long-range dependencies context due to consecutive convolution striding and pooling operations inside CNNs. In this paper, we formulate a cascaded context enhancement neural network for automatic skin lesion segmentation. A new cascaded context aggregation (CCA) module with a gate-based information integration approach is proposed to sequentially and selectively aggregate original image and multi-level features from the encoder sub-network. The generated context is further utilized to guide discriminative features extraction by the designed context-guided local affinity (CGL) module. Furthermore, an auxiliary loss is added to the CCA module for refining the prediction. In our work, we evaluate our approach on four public skin dermoscopy image datasets. The proposed method achieves the Jaccard Index (JA) of 87.1%, 80.3%, 84.3%, and 86.6% on ISIC-2016, ISIC-2017, ISIC-2018, and PH2 datasets, which show highly competitive performance with other state-of-the-art models respectively. </p></div>
    <!-- <p style="margin:0"><button class="accordion">
      Online Appendix
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> <a href="https://tyleransom.github.io/research/SCEonlineAppendix.pdf">Online Appendix</a> </p></div> -->
    <p style="margin:0"><button class="accordion">
      Replication files
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> Data &amp; code for replication</p></div>
    <!-- <p style="margin:0"><button class="accordion">
      Other versions
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> <a href="https://tyleransom.github.io/research/SCE_migration.pdf">Preprint</a> (June 22, 2020) <br> <a href="http://www.cesifo.org/DocDL/cesifo1_wp8117_0.pdf">CESifo Working Paper No. 8117</a> (February 2020) <br> <a href="https://www.newyorkfed.org/research/staff_reports/sr883.html">New York Fed Staff Report No. 883</a> (April 2019) <br> <a href="http://ftp.iza.org/dp12271.pdf">IZA Discussion Paper No. 12271</a> (April 2019) </p></div>
    <p style="margin:0"><button class="accordion">
      Media coverage
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> <a href="https://www.citylab.com/life/2019/05/moving-location-new-city-how-much-cost-mobile-rooted-stuck/590521/"><i>CityLab</i></a> </p></div><br> -->
    <hr>
    <p style="margin:0"> <a style="margin:0; font-size:100%; font-weight:bold" href="https://www.sciencedirect.com/science/article/pii/S0925231222004404">Perturb more, trap more: Understanding behaviors of graph neural networks</a> <br> Ji, C., <b>Wang, R.</b>, and Wu, H. <br> <i>Neurocomputing</i>, 493: 59-75, 2022. </i><br><button class="accordion">
    Abstract
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> While graph neural networks (GNNs) have shown great potential in various graph-related tasks, their lack of transparency has hindered our understanding of how they arrive at their predictions. The fidelity to the local decision boundary of the original model, indicating how well the explainer fits the original model around the instance to be explained, is neglected by existing GNN explainers. In this paper, we first propose a novel post hoc framework based on local fidelity for any trained GNNs, called TraP2, which can generate a high-fidelity explanation. Considering that both the relevant graph structure and important features inside each node must be highlighted, a three-layer architecture in TraP2 is designed: i) the interpretation domain is defined by the Translation layer in advance; ii) the local predictive behaviors of the GNNs being explained are probed and monitored by the Perturbation layer, in which multiple perturbations for graph structure and feature level are conducted in the interpretation domain; and iii) highly faithful explanations are generated by fitting the local decision boundary of GNNs being explained through the Paraphrase layer. We evaluated TraP2 on several benchmark datasets under the four metrics of accuracy, area under receiver operating characteristic curve, fidelity, and contrastivity, and the results prove that it significantly outperforms state-of-the-art methods. </p></div>
    <!-- <p style="margin:0"><button class="accordion">
      Online Appendix
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> <a href="https://tyleransom.github.io/research/RecruitRejectOnlineAppendix.pdf">Online Appendix</a> </p></div> -->
    <p style="margin:0"><button class="accordion">
      Replication files
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> <a href="https://github.com/aI-area/TraP2">Data &amp; code for replication</a> </p></div>
    <!-- <p style="margin:0"><button class="accordion">
      Other versions
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> <br>  <a href="https://tyleransom.github.io/research/recruit_reject.pdf">Accepted version</a> (April 2022) <br> <a href="http://www.nber.org/papers/w26456">NBER Working Paper No. 26456</a> (November 2019) <br> <a href="https://www.iza.org/publications/dp/12750/recruit-to-reject-harvard-and-african-american-applicants">IZA Discussion Paper No. 12750</a> (November 2019) <br> <a href="https://hceconomics.uchicago.edu/research/working-paper/recruit-reject-harvard-and-african-american-applicants">HCEO Working Paper No. 2019-074</a> (December 2019) </p></div> -->
    <!-- <p style="margin:0"><button class="accordion">
      Media coverage
    </button> -->
    <!-- <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> <a href="https://www.nytimes.com/2019/11/29/us/harvard-admissions-recruit-letter.html"><i>New York Times</i></a> <br> <a href="https://marginalrevolution.com/marginalrevolution/2019/11/harvard-sentences-to-ponder.html"><i>Marginal Revolution</i></a> <br> <a href="https://www.insidehighered.com/admissions/article/2019/11/25/harvard-faces-scrutiny-black-applicants-it-rejects"><i>Inside Higher Ed</i></a> <br> <a href="https://www.thecrimson.com/article/2019/11/20/Arcidiacono-working-paper/"><i>Harvard Crimson</i></a> <br> <a href="https://www.nationalreview.com/corner/is-harvard-leading-on-black-applicants/"><i>National Review</i></a> <br> <a href="https://freebeacon.com/issues/harvard-recruited-to-reject-thousands-of-black-kids-study-shows/"><i>Washington Free Beacon</i></a> <br> <a href="https://www.jbhe.com/2019/11/study-charges-harvard-with-recruiting-black-applicants-who-have-no-chance-of-admission">The <i>Journal of Blacks in Higher Education</i></a> </p></div><br> -->
    <hr>
    <p style="margin:0"> <a style="margin:0; font-size:100%; font-weight:bold" href="https://ieeexplore.ieee.org/abstract/document/9625743">Focus, Fusion, and Rectify: Context-Aware Learning for COVID-19 Lung Infection Segmentation</a> <br> <b>Wang, R.</b>, Ji, C., Zhang, Y., and Li, Y.<br> <i>IEEE Transactions on Neural Networks and Learning Systems</i>, 33(1): 12-24, 2021. <br><button class="accordion">
    Abstract
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> The coronavirus disease 2019 (COVID-19) pandemic is spreading worldwide. Considering the limited clinicians and resources and the evidence that computed tomography (CT) analysis can achieve comparable sensitivity, specificity, and accuracy with reverse-transcription polymerase chain reaction, the automatic segmentation of lung infection from CT scans supplies a rapid and effective strategy for COVID-19 diagnosis, treatment, and follow-up. It is challenging because the infection appearance has high intraclass variation and interclass indistinction in CT slices. Therefore, a new context-aware neural network is proposed for lung infection segmentation. Specifically, the autofocus and panorama modules are designed for extracting fine details and semantic knowledge and capturing the long-range dependencies of the context from both peer level and cross level. Also, a novel structure consistency rectification is proposed for calibration by depicting the structural relationship between foreground and background. Experimental results on multiclass and single-class COVID-19 CT images demonstrate the effectiveness of our work. In particular, our method obtains the mean intersection over union (mIoU) score of 64.8%, 65.2%, and 73.8% on three benchmark datasets for COVID-19 infection segmentation. </p></div>

    <p style="margin:0"><button class="accordion">
      Replication files
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> <a href="https://github.com/mathwrx/Focus-Fusion-and-Rectify-Context-Aware-Learning-for-COVID-19-Lung-Infection-Segmentation">Data &amp; code for replication</a></p></div>


    <hr>
    <p style="margin:0"> <a style="margin:0; font-size:100%; font-weight:bold" href="https://ieeexplore.ieee.org/document/9514513">Smoothness Sensor: Adaptive Smoothness-transition Graph Convolution for Attributed Graph Clustering</a> <br> Ji C., Chen H., <b>Wang R.</b>, Cai Y., Wu H.<br> <i>IEEE Transactions on Cybernetics</i>, Early Access, 2021. <br><button class="accordion">
    Abstract
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> Clustering techniques attempt to group objects with similar properties into a cluster. Clustering the nodes of an attributed graph, in which each node is associated with a set of feature attributes, has attracted significant attention. Graph convolutional networks (GCNs) represent an effective approach for integrating the two complementary factors of node attributes and structural information for attributed graph clustering. Smoothness is an indicator for assessing the degree of similarity of feature representations among nearby nodes in a graph. Oversmoothing in GCNs, caused by unnecessarily high orders of graph convolution, produces indistinguishable representations of nodes, such that the nodes in a graph tend to be grouped into fewer clusters, and pose a challenge due to the resulting performance drop. In this study, we propose a smoothness sensor for attributed graph clustering based on adaptive smoothness-transition graph convolutions, which senses the smoothness of a graph and adaptively terminates the current convolution once the smoothness is saturated to prevent oversmoothing. Furthermore, as an alternative to graph-level smoothness, a novel fine-grained nodewise-level assessment of smoothness is proposed, in which smoothness is computed in accordance with the neighborhood conditions of a given node at a certain order of graph convolution. In addition, a self-supervision criterion is designed considering both the tightness within clusters and the separation between clusters to guide the entire neural network training process. The experiments show that the proposed methods significantly outperform 13 other state-of-the-art baselines in terms of different metrics across five benchmark datasets. In addition, an extensive study reveals the reasons for their effectiveness and efficiency. </p></div>

    <p style="margin:0"><button class="accordion">
      Replication files
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> <a href="https://github.com/aI-area/NASGC">Data &amp; code for replication</a></p></div>


    <hr>
    <p style="margin:0"> <a style="margin:0; font-size:100%; font-weight:bold" href="https://ieeexplore.ieee.org/document/9537642">Graph Polish: A Novel Graph Generation Paradigm for Molecular Optimization</a> <br>Ji C., Zheng Y., <b>Wang R.</b>, Cai Y., Wu H.<br> <i>IEEE Transactions on Neural Networks and Learning Systems</i>, Early Access, 2021. <br><button class="accordion">
    Abstract
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> Molecular optimization, which transforms a given input molecule X into another Y with desired properties, is essential in molecular drug discovery. The traditional approaches either suffer from sample-inefficient learning or ignore information that can be captured with the supervised learning of optimized molecule pairs. In this study, we present a novel molecular optimization paradigm, Graph Polish. In this paradigm, with the guidance of the source and target molecule pairs of the desired properties, a heuristic optimization solution can be derived: given an input molecule, we first predict which atom can be viewed as the optimization center, and then the nearby regions are optimized around this center. We then propose an effective and efficient learning framework, Teacher and Student polish, to capture the dependencies in the optimization steps. A teacher component automatically identifies and annotates the optimization centers and the preservation, removal, and addition of some parts of the molecules; a student component learns these knowledges and applies them to a new molecule. The proposed paradigm can offer an intuitive interpretation for the molecular optimization result. Experiments with multiple optimization tasks are conducted on several benchmark datasets. The proposed approach achieves a significant advantage over the six state-of-the-art baseline methods. Also, extensive studies are conducted to validate the effectiveness, explainability, and time savings of the novel optimization paradigm. </p></div>

    <p style="margin:0"><button class="accordion">
      Replication files
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> <a href="https://github.com/aI-area/T-S-polish">Data &amp; code for replication</a></p></div>
    <hr>



    <p style="margin:0"> <a style="margin:0; font-size:100%; font-weight:bold" href="https://ieeexplore.ieee.org/document/9371309">A Short-term Prediction Model at the Early Stage of the COVID-19 Pandemic based on Multi-source Urban Data</a> <br> <b>Wang, R.</b>, Ji, C., Jiang, Z., Wu, Y., Yin, L., and Li, Y.<br> <i>IEEE Transactions on Computational Social Systems</i>, 8(4): 938-945, 2021. <br><button class="accordion">
    Abstract
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> The ongoing coronavirus disease 2019 (COVID-19) pandemic spread throughout China and worldwide since it was reported in Wuhan city, China in December 2019. 4 589 526 confirmed cases have been caused by the pandemic of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), by May 18, 2020. At the early stage of the pandemic, the large-scale mobility of humans accelerated the spread of the pandemic. Rapidly and accurately tracking the population inflow from Wuhan and other cities in Hubei province is especially critical to assess the potential for sustained pandemic transmission in new areas. In this study, we first analyze the impact of related multisource urban data (such as local temperature, relative humidity, air quality, and inflow rate from Hubei province) on daily new confirmed cases at the early stage of the local pandemic transmission. The results show that the early trend of COVID-19 can be explained well by human mobility from Hubei province around the Chinese Lunar New Year. Different from the commonly-used pandemic models based on transmission dynamics, we propose a simple but effective short-term prediction model for COVID-19 cases, considering the human mobility from Hubei province to the target cities. The performance of our proposed model is validated by several major cities in Guangdong province. For cities like Shenzhen and Guangzhou with frequent population flow per day, the values of R^2 of daily prediction achieve 0.988 and 0.985. The proposed model has provided a reference for decision support of pandemic prevention and control in Shenzhen. </p></div>

    <p style="margin:0"><button class="accordion">
      Replication files
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p>Data &amp; code for replication</p></div>

    <hr>
    <p style="margin:0"> <a style="margin:0; font-size:100%; font-weight:bold" href="https://www.sciencedirect.com/science/article/pii/S0010482521002766">Improving influenza surveillance based on multi-granularity deep spatiotemporal neural network</a> <br> <b>Wang, R.</b>, Wu, H., Wu, Y., Zheng, J., and Li, Y.<br> <i>Computers in Biology and Medicine</i>, 134: 104482, 2021. <br><button class="accordion">
    Abstract
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> Influenza is a common respiratory disease that can cause human illness and death. Timely and accurate prediction of disease risk is of great importance for public health management and prevention. The influenza data belong to typical spatiotemporal data in that influenza transmission is influenced by regional and temporal interactions. Many existing methods only use the historical time series information for prediction, which ignores the effect of spatial correlations of neighboring regions and temporal correlations of different time periods. Mining spatiotemporal information for risk prediction is a significant and challenging issue. In this paper, we propose a new end-to-end spatiotemporal deep neural network structure for influenza risk prediction. The proposed model mainly consists of two parts. The first stage is the spatiotemporal feature extraction stage where two-stream convolutional and recurrent neural networks are constructed to extract the different regions and time granularity information. Then, a dynamically parametric-based fusion method is adopted to integrate the two-stream features and making predictions. In our work, we demonstrate that our method, tested on two influenza-like illness (ILI) datasets (US-HHS and SZ-HIC), achieved the best performance across all evaluation metrics. The results imply that our method has outstanding performance for spatiotemporal feature extraction and enables accurate predictions compared to other well-known influenza forecasting models.</p></div>

    <!-- <p style="margin:0"><button class="accordion">
      Replication files
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p>Data &amp; code for replication</p></div> -->
    <hr>

    <p style="margin:0"> <a style="margin:0; font-size:100%; font-weight:bold" href="https://www.sciencedirect.com/science/article/pii/S0010482521002766">Myocardial Infarction Detection and Localization with Electrocardiogram Based on Convolutional Neural Network</a> <br> Liu, J., <b>Wang, R.</b>, Wen, B., Liu, Z., Miao, F., and Li, Y.<br> <i>Chinese Journal of Electronics</i>, 30(5): 833-842, 2021. <br><button class="accordion">
    Abstract
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> Electrocardiogram (ECG) is widely used in Myocardial infarction (MI) diagnosis. The automatic diagnosis of MI based on the 12-lead ECG needs to consider not only the waveform change features in multi-resolution time series, but also the spatial correlation information between the leads. To this end, this work proposed multiscale spatiotemporal feature extraction method based on Convolutional neural network (CNN) for MI automatic diagnosis. First, the 12-lead ECG is first transformed into an ECG image through wavelet decomposition and 3-dimensional space reconstruction. The MI-CNN model is then constructed to identify MI using 41368 ECG images. Finally, we develop the LL-CNN model, which is utilized only after the ECG signal is identified as an MI event by the MI-CNN model, to localize MI by employing transfer learning to overcome the limited data problem. The proposed method has achieved an accuracy of 99.51% on MI detection, and a macro-F1 of 99.14% on MI localization. Moreover, the features visualization shows that U-wave has significant diagnostic value for MI. The proposed method significantly improves the performance of MI detection and localization compared with other methods. It is promising to be used for MI monitoring and diagnosis.</p></div>

    <!-- <p style="margin:0"><button class="accordion">
      Replication files
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p>Data &amp; code for replication</p></div> -->
    <hr>

    <!-- <p style="margin:0"> <a style="margin:0; font-size:100%; font-weight:bold" href="https://www.sciencedirect.com/science/article/pii/S0010482521002766">Multi-class Arrhythmia detection from 12-lead varied-length ECG using Attention-based Time-Incremental Convolutional Neural Network</a> <br> <b>Wang, R.</b>, Wu, H., Wu, Y., Zheng, J., and Li, Y.<br> <i>Computers in Biology and Medicine</i>, 134: 104482, 2021. <br><button class="accordion">
    Abstract
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> nfluenza is a common respiratory disease that can cause human illness and death. Timely and accurate prediction of disease risk is of great importance for public health management and prevention. The influenza data belong to typical spatiotemporal data in that influenza transmission is influenced by regional and temporal interactions. Many existing methods only use the historical time series information for prediction, which ignores the effect of spatial correlations of neighboring regions and temporal correlations of different time periods. Mining spatiotemporal information for risk prediction is a significant and challenging issue. In this paper, we propose a new end-to-end spatiotemporal deep neural network structure for influenza risk prediction. The proposed model mainly consists of two parts. The first stage is the spatiotemporal feature extraction stage where two-stream convolutional and recurrent neural networks are constructed to extract the different regions and time granularity information. Then, a dynamically parametric-based fusion method is adopted to integrate the two-stream features and making predictions. In our work, we demonstrate that our method, tested on two influenza-like illness (ILI) datasets (US-HHS and SZ-HIC), achieved the best performance across all evaluation metrics. The results imply that our method has outstanding performance for spatiotemporal feature extraction and enables accurate predictions compared to other well-known influenza forecasting models.</p></div>
    <hr> -->


    <p style="margin:0"> <a style="margin:0; font-size:100%; font-weight:bold" href="https://ieeexplore.ieee.org/abstract/document/9064540/">Deep Multi-Scale Fusion Neural Network for Multi-Class Arrhythmia Detection</a> <br> <b>Wang, R.</b>, Fan, J., and Li, Y.<br> <i>IEEE Journal of Biomedical and Health Informatics</i>, 24(9): 2461-2472, 2020. <br><button class="accordion">
    Abstract
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> Automated electrocardiogram (ECG) analysis for arrhythmia detection plays a critical role in early prevention and diagnosis of cardiovascular diseases. Extracting powerful features from raw ECG signals for fine-grained diseases classification is still a challenging problem today due to variable abnormal rhythms and noise distribution. For ECG analysis, the previous research works depend mostly on heartbeat or single scale signal segments, which ignores underlying complementary information of different scales. In this paper, we formulate a novel end-to-end Deep Multi-Scale Fusion convolutional neural network (DMSFNet) architecture for multi-class arrhythmia detection. Our proposed approach can effectively capture abnormal patterns of diseases and suppress noise interference by multi-scale feature extraction and cross-scale information complementarity of ECG signals. The proposed method implements feature extraction for signal segments with different sizes by integrating multiple convolution kernels with different receptive fields. Meanwhile, joint optimization strategy with multiple losses of different scales is designed, which not only learns scale-specific features, but also realizes cumulatively multi-scale complementary feature learning during the learning process. In our work, we demonstrate our DMSFNet on two open datasets (CPSC_2018 and PhysioNet/CinC_2017) and deliver the state-of-art performance on them. Among them, CPSC_2018 is a 12-lead ECG dataset and CinC_2017 is a single-lead dataset. For these two datasets, we achieve the F1 score 82.8% and 84.1% which are higher than previous state-of-art approaches respectively. The results demonstrate that our end-to-end DMSFNet has outstanding performance for feature extraction from a broad range of distinct arrhythmias and elegant generalization ability for effectively handling ECG signals with different leads.</p></div>

    <!-- <p style="margin:0"><button class="accordion">
      Replication files
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p>Data &amp; code for replication</p></div> -->
    <hr>

    <p style="margin:0"> <a style="margin:0; font-size:100%; font-weight:bold" href="https://www.sciencedirect.com/science/article/pii/S1566253518307632">Multi-class Arrhythmia detection from 12-lead varied-length ECG using Attention-based Time-Incremental Convolutional Neural Network</a> <br> Yao, Q., <b>Wang, R.</b>, Fan, X., Liu, J., and Li, Y.<br> <i>Information Fusion</i>, 53: 174-182, 2020. <br><button class="accordion">
    Abstract
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> Automatic arrhythmia detection from Electrocardiogram (ECG) plays an important role in early prevention and diagnosis of cardiovascular diseases. Convolutional neural network (CNN) is a simpler, more noise-immune solution than traditional methods in multi-class arrhythmia classification. However, suffering from lack of consideration for temporal feature of ECG signal, CNN couldn’t accept varied-length ECG signal and had limited performance in detecting paroxysmal arrhythmias. To address these issues, we proposed attention-based time-incremental convolutional neural network (ATI-CNN), a deep neural network model achieving both spatial and temporal fusion of information from ECG signals by integrating CNN, recurrent cells and attention module. Comparing to CNN model, this model features flexible input length, halved parameter amount as well as more than 90% computation reduction in real-time processing. The experiment result shows that, ATI-CNN reached an overall classification accuracy of 81.2%. In comparison with a classical 16-layer CNN named VGGNet, ATI-CNN achieved accuracy increases of 7.7% in average and up to 26.8% in detecting paroxysmal arrhythmias. Combining all these excellent features, ATI-CNN offered an exemplification for all kinds of varied-length signal processing problems.</p></div>

    <!-- <p style="margin:0"><button class="accordion">
      Replication files
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p>Data &amp; code for replication</p></div> -->
    <hr>

    <!-- <p style="margin:0"> <a style="margin:0; font-size:100%; font-weight:bold" href="https://www.sciencedirect.com/science/article/pii/S0010482521002766">Multi-class Arrhythmia detection from 12-lead varied-length ECG using Attention-based Time-Incremental Convolutional Neural Network</a> <br> <b>Wang, R.</b>, Wu, H., Wu, Y., Zheng, J., and Li, Y.<br> <i>Computers in Biology and Medicine</i>, 134: 104482, 2021. <br><button class="accordion">
    Abstract
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> nfluenza is a common respiratory disease that can cause human illness and death. Timely and accurate prediction of disease risk is of great importance for public health management and prevention. The influenza data belong to typical spatiotemporal data in that influenza transmission is influenced by regional and temporal interactions. Many existing methods only use the historical time series information for prediction, which ignores the effect of spatial correlations of neighboring regions and temporal correlations of different time periods. Mining spatiotemporal information for risk prediction is a significant and challenging issue. In this paper, we propose a new end-to-end spatiotemporal deep neural network structure for influenza risk prediction. The proposed model mainly consists of two parts. The first stage is the spatiotemporal feature extraction stage where two-stream convolutional and recurrent neural networks are constructed to extract the different regions and time granularity information. Then, a dynamically parametric-based fusion method is adopted to integrate the two-stream features and making predictions. In our work, we demonstrate that our method, tested on two influenza-like illness (ILI) datasets (US-HHS and SZ-HIC), achieved the best performance across all evaluation metrics. The results imply that our method has outstanding performance for spatiotemporal feature extraction and enables accurate predictions compared to other well-known influenza forecasting models.</p></div>
    <hr>
     -->


    <!-- <p style="margin:0"> <a style="margin:0; font-size:100%; font-weight:bold" href="https://link.springer.com/article/10.1007/s10589-017-9931-8">Shrinking gradient descent algorithms for total variation regularized image denoising</a> <br> Li, M., Han, C., <b>Wang, R.</b>, and Guo, T.<br> <i>Computational Optimization and Applications</i>, 68: 643–660, 2017. <br><button class="accordion">
    Abstract
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> Total variation regularization introduced by Rudin, Osher, and Fatemi (ROF) is widely used in image denoising problems for its capability to preserve repetitive textures and details of images. Many efforts have been devoted to obtain efficient gradient descent schemes for dual minimization of ROF model, such as Chambolle’s algorithm or gradient projection (GP) algorithm. In this paper, we propose a general gradient descent algorithm with a shrinking factor. Both Chambolle’s and GP algorithm can be regarded as the special cases of the proposed methods with special parameters. Global convergence analysis of the new algorithms with various step lengths and shrinking factors are present. Numerical results demonstrate their competitiveness in computational efficiency and reconstruction quality with some existing classic algorithms on a set of gray scale images.</p></div>


    <hr> -->







    <h2><a id="works-in-progress" class="anchor" href="#workinprogress" aria-hidden="true"><span class="octicon octicon-link"></span></a>Works in Progress</h2>

    <!-- <p style="margin:0"> <b>Hopgat: Hop-aware supervision graph attention networks for sparsely labeled graphs</b> <br> -->
      <!-- Abstract -->
    <!-- </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> Does temperature affect real economic activity? Using the annual Current Population Survey between 1963 and 2015, we show that there is no association between temperature and earnings, hours, or output after controlling for time-invariant spatial heterogeneity and time-varying demographic factors. These results are robust to five separate sources of micro-data, different sampling horizons, functional forms, spatial measures of temperature, and subsets of the data. This paper studies the relationship between temperature and productivity across space and time. Motivated by these null results, we develop a spatial equilibrium model where temperature can affect not only firm productivity, but also individual locational choice. After calibrating the model, we use it to disentangle the role of reallocation versus actual productivity losses in the U.S. economy between 1980 and 2015. Nearly all of the variation is driven by reallocation. We subsequently use the model to evaluate a counterfactual climate scenario and recover a new spatial equilibrium for the U.S. economy by 2050. </p></div><br>

    <p style="margin:0"> <b>The Role of Supply and Demand Factors in Explaining the Migration of College Majors</b> <br> with <a href="https://www.linkedin.com/in/joel-p-t-mcguire/">Joel McGuire</a>. <br><button class="accordion">
      Abstract
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> This paper examines location as an outcome of college major choice. We document substantial differences in the spatial availability of college majors. These differences explain much of the cross-major variation in unemployment and migration, but not earnings. Using a natural experiment, we show that migration differences across majors appear to be driven by labor demand and not labor supply.</p></div><br>

    <p style="margin:0"> <b>Minorities in STEM: The Role of Ability Revelation</b> <br> with <a href="http://www.nickchk.com/">Nick Huntington-Klein</a>. <br><button class="accordion">
      Abstract
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> Coming soon.</p></div><br> -->

      </section>
    </div>
    <script src="javascripts/scale.fix.js"></script>
    <script>
    var acc = document.getElementsByClassName("accordion");
    var i;

    for (i = 0; i < acc.length; i++) {
        acc[i].onclick = function(){
            this.classList.toggle("active");
            this.parentNode.nextElementSibling.classList.toggle("show");
      }
    }
    </script>
  </body>
</html>
